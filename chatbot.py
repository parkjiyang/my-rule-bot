import streamlit as st
import json
import os
import re
import numpy as np
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import google.generativeai as genai

# --- 1. ì„¤ì • ë° UI ìµœì í™” ---
st.set_page_config(layout="centered", page_title="ì—…ë¬´ê·œì • AI", page_icon="ğŸ”—")
st.markdown("""
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <style>
        .main .block-container {
            padding-top: 2rem; padding-left: 1rem; padding-right: 1rem;
        }
        .stButton>button {
            height: 3.5em; font-size: 1.1em; font-weight: bold; border-radius: 10px;
        }
        .stChatMessage {
            border-radius: 10px; padding: 1em 1.2em; margin-bottom: 1em;
            border: 1px solid #e0e0e0; box-shadow: 0 1px 3px rgba(0,0,0,0.05);
        }
    </style>
""", unsafe_allow_html=True)

# (ì¹´í…Œê³ ë¦¬ ì •ì˜ ë° íŒŒì¼ ë¡œë”© í•¨ìˆ˜ë“¤ì€ ì´ì „ê³¼ ë™ì¼)
CATEGORIES = {
    "1": {"name": "ê¸°ë³¸ë²•ê·œ", "files": ["í•œêµ­êµí†µì•ˆì „ê³µë‹¨ ì •ê´€"]},
    "2": {"name": "ì¡°ì§", "files": ["êµ­ì™¸ì‚¬ë¬´ì†Œ ìš´ì˜ì„¸ì¹™", "ìœ„ì„ì „ê²°ê·œì •", "ì´ì‚¬íšŒê·œì •", "ìë™ì°¨ì•ˆì „ì—°êµ¬ì› ìš´ì˜ê·œì •", "ìë™ì°¨ì•ˆì „ì—°êµ¬ì› ìœ„ì„ì „ê²°ì„¸ì¹™", "ìë™ì°¨ì•ˆì „ì—°êµ¬ì› ì§ì œì‹œí–‰ì„¸ì¹™", "ì§ì œê·œì •", "ì§ì œì‹œí–‰ì„¸ì¹™"]},
    "3": {"name": "ì¸ì‚¬", "files": ["ì¸ì‚¬ê´€ë¦¬ì„¸ì¹™", "ì¸ì‚¬ê·œì •", "ì„ê¸ˆí”¼í¬ì œ ìš´ì˜ê·œì •", "ì„ì› ì¶”ì²œìœ„ì›íšŒ ìš´ì˜ê·œì •", "ìë™ì°¨ì•ˆì „ì—°êµ¬ì› ì¸ì‚¬ì„¸ì¹™", "ì±„ìš©ì—…ë¬´ì²˜ë¦¬ì„¸ì¹™", "ì·¨ì—…ê·œì •", "ë³´ì§ê´€ë¦¬ì— ê´€í•œì§€ì¹¨", "ì•ˆì „ì‚¬ê³ ì— ê´€í•œ ì„ì› ë¬¸ì±… ê·œì •"]},
    "4": {"name": "ë³´ìˆ˜,ë³µë¦¬", "files": ["ìƒì‚¬ë£Œë“±ì œìˆ˜ë‹¹ì§€ê¸‰ì„¸ì¹™", "ê²½ì˜ì„±ê³¼ì§€ê¸‰ì§€ì¹¨", "ë³´ìˆ˜ê·œì •", "ë³µë¦¬í›„ìƒê·œì •", "ì‹¤ë¬´ì§ê·¼ë¡œì ë° ê¸°ê°„ì œê·¼ë¡œì ê´€ë¦¬ê·œì •"]},
    "5": {"name": "ì¬ë¬´,ê³„ì•½", "files": ["ê³„ì•½ì‚¬ë¬´ì²˜ë¦¬ì„¸ì¹™", "ì˜ˆì‚°íšŒê³„ê·œì •", "ìê¸ˆìš´ìš©ì—…ë¬´ì—ê´€í•œì„¸ì¹™", "íˆ¬ì ë° ìê¸ˆìš´ìš©ì—…ë¬´ ì‹¬ì‚¬ì— ê´€í•œ ì„¸ì¹™"]},
    "6": {"name": "ì†Œì†¡,ê·œì •", "files": ["ì†Œì†¡ì—…ë¬´ì²˜ë¦¬ê·œì •", "ì„ì§ì›ì†Œì†¡ì§€ì›ê·œì •", "ì œê·œì •ê´€ë¦¬ê·œì •"]},
    "7": {"name": "ìœ¤ë¦¬,ì¸ê¶Œ", "files": ["ê³µì •ê±°ë˜ììœ¨ì¤€ìˆ˜í”„ë¡œê·¸ë¨ ìš´ì˜ê·œì •", "ê¸°ì—…ì„±ì¥ì‘ë‹µì„¼í„° ìš´ì˜ê·œì •", "ì„ì›ì§ë¬´ì²­ë ´ê³„ì•½ìš´ì˜ê·œì •"]},
    "8": {"name": "ê°ì‚¬", "files": ["ê°ì‚¬ê·œì •", "ë‚´ë¶€í†µì œê·œì •", "ë¶€ì •ì²­íƒ ë° ê¸ˆí’ˆ ë“± ìˆ˜ìˆ˜ì˜ ì‹ ê³  ì‚¬ë¬´ ì²˜ë¦¬ ì§€ì¹¨", "ì´í•´ì¶©ëŒë°©ì§€ì œë„ ìš´ì˜ì§€ì¹¨"]},
    "9": {"name": "ì•ˆì „,ë³´ê±´", "files": ["ì•ˆì „ë³´ê±´ê´€ë¦¬ê·œì •"]},
    "10": {"name": "ë³´ì•ˆ", "files": ["ë³´ì•ˆì—…ë¬´ê·œì¹™"]},
    "11": {"name": "ì¼ë°˜í–‰ì •", "files": ["ê¸°ì—…ë¯¼ì› ë³´í˜¸ì„œë¹„ìŠ¤ í—Œì¥ ìš´ì˜ê·œì •", "ë¯¼ì›ì²˜ë¦¬ê·œì •", "ì—¬ë¹„ê·œì •", "ì²­ì›ì‹¬ì˜íšŒ ìš´ì˜ê·œì •", "í–‰ì •ì—…ë¬´ì˜ íš¨ìœ¨ì  ìš´ì˜ì— ê´€í•œ ê·œì •"]},
    "12": {"name": "ìê²©,êµìœ¡", "files": ["ë¯¼ê°„ìê²©ê´€ë¦¬ìš´ì˜ì„¸ì¹™", "ìš´ì „ì ì„±ì •ë°€ê²€ì‚¬ ìš´ì˜ì„¸ì¹™", "ì´ˆê²½ëŸ‰ë¹„í–‰ì¥ì¹˜ ì¡°ì¢…ì ì¦ëª… ìš´ì˜ì„¸ì¹™", "êµ­ê°€ìê²©ì‹œí—˜ê´€ë¦¬ì„¸ì¹™", "ë¬´ì¸ë¹„í–‰ì¥ì¹˜ ì „ë¬¸êµìœ¡ê¸°ê´€ì§€ì • ë° ê´€ë¦¬ì—…ë¬´ ìš´ì˜ì„¸ì¹™", "ë¬´ì¸ë¹„í–‰ì¥ì¹˜ ì¡°ì¢…ì ì¦ëª… ìš´ì˜ì„¸ì¹™"]},
    "13": {"name": "ì² ë„", "files": ["ì •ë°€ì§„ë‹¨ ì„±ëŠ¥í‰ê°€ ê²°ê³¼ë³´ê³ ì„œ í‰ê°€ ê·œì •"]},
    "14": {"name": "ì—°êµ¬", "files": ["ì—°êµ¬ê´€ë¦¬ê·œì •", "ìš©ì—­ì—…ë¬´ìˆ˜íƒì—ê´€í•œì„¸ì¹™", "ìë™ì°¨ì•ˆì „ì—°êµ¬ì› ì—…ë¬´ì„¸ì¹™"]},
    "15": {"name": "ê¸°íƒ€ì‚¬ì—…", "files": ["ì‚¬ë‚´ë²¤ì²˜ ìš´ì˜ê·œì •", "ì´ˆê²½ëŸ‰ë¹„í–‰ì¥ì¹˜ ì‹ ê³ ì—…ë¬´ ìš´ì˜ì„¸ì¹™", "íŠœë‹ë¶€í’ˆ ì•ˆì „í™•ì¸ ì—…ë¬´ ë“±ì— ê´€í•œ ê·œì •"]},
}
ALL_FILES = list(set([file for category in CATEGORIES.values() for file in category['files']]))
JSON_FILE_PATH = 'í†µí•©_ìˆ˜ì •ì™„ë£Œ.json'

@st.cache_resource
def load_sbert_model():
    return SentenceTransformer('jhgan/ko-sbert-nli')

@st.cache_data
def load_and_embed_data(path, _model):
    # This function is the same as the last version
    try:
        with open(path, 'r', encoding='utf-8') as f: data = json.load(f)
    except: return None
    processed_docs = []
    for item in data:
        file_name = item.get('fileName', '')
        regulation_name = os.path.splitext(file_name)[0]
        regulation_name = re.sub(r'\(.*\)', '', regulation_name).strip()
        full_page_text = []
        for page in item.get('pages', []):
            for content_block in page.get('content', []):
                if content_block.get('type') == 'paragraph': full_page_text.append(content_block.get('data', ''))
                elif content_block.get('type') == 'table':
                    table_data = content_block.get('data', []); table_text = ' '.join([' '.join(map(str, row)) for row in table_data]); full_page_text.append(f"[í‘œ ë‚´ìš©] {table_text}")
        final_text = "\n".join(full_page_text)
        if final_text: processed_docs.append({"ê·œì •ëª…": regulation_name, "ë‚´ìš©": final_text, "id": len(processed_docs)})
    if not processed_docs: return None
    contents = [doc['ë‚´ìš©'] for doc in processed_docs]
    embeddings = _model.encode(contents, convert_to_tensor=True, show_progress_bar=True)
    return {"docs": processed_docs, "embeddings": embeddings.cpu().numpy()}

# --- 2. ê²€ìƒ‰ ë° ë‹µë³€ ìƒì„± ì—”ì§„ ---
def hybrid_search(query, data, model, selected_files, top_k=3):
    # This function is the same as the last version
    query_keywords = set(query.split())
    docs_to_search = [doc for doc in data['docs'] if any(doc['ê·œì •ëª…'].startswith(f) for f in selected_files)]
    keyword_results = []
    for doc in docs_to_search:
        doc_words = set(doc['ë‚´ìš©'].split()); matched_keywords = query_keywords.intersection(doc_words)
        if matched_keywords: keyword_results.append({'doc': doc, 'score': len(matched_keywords)})
    keyword_results = sorted(keyword_results, key=lambda x: x['score'], reverse=True)
    query_embedding = model.encode(query, convert_to_tensor=True).cpu().numpy()
    indices_to_search = [i for i, doc in enumerate(data['docs']) if any(doc['ê·œì •ëª…'].startswith(f) for f in selected_files)]
    if not indices_to_search: return []
    filtered_docs_for_semantic = [data['docs'][i] for i in indices_to_search]
    filtered_embeddings = data['embeddings'][indices_to_search]
    semantic_similarities = cosine_similarity(query_embedding.reshape(1, -1), filtered_embeddings)[0]
    fused_scores = {}; k = 60
    semantic_top_indices = np.argsort(semantic_similarities)[::-1]
    for rank, idx in enumerate(semantic_top_indices):
        doc_id = filtered_docs_for_semantic[idx]['id']
        if doc_id not in fused_scores: fused_scores[doc_id] = 0
        fused_scores[doc_id] += 1 / (k + rank + 1)
    for rank, res in enumerate(keyword_results):
        doc_id = res['doc']['id']
        if doc_id not in fused_scores: fused_scores[doc_id] = 0
        fused_scores[doc_id] += 1 / (k + rank + 1)
    if not fused_scores: return []
    sorted_doc_ids = sorted(fused_scores.keys(), key=lambda id: fused_scores[id], reverse=True)
    id_to_doc = {doc['id']: doc for doc in data['docs']}
    return [id_to_doc[doc_id] for doc_id in sorted_doc_ids[:top_k]]

def generate_ultimate_answer(query, context_docs, chat_history):
    try:
        # âœ¨ ë°°í¬ë¥¼ ìœ„í•´ Streamlitì˜ Secretsì—ì„œ API í‚¤ë¥¼ ê°€ì ¸ì˜¤ë„ë¡ ìˆ˜ì •
        api_key = st.secrets.get("GOOGLE_API_KEY")
        if not api_key:
            return "ì˜¤ë¥˜: ê´€ë¦¬ìê°€ ì•±ì— API í‚¤ë¥¼ ì„¤ì •í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-1.5-flash')
        
        context_str = "\n\n---\n\n".join([f"ë¬¸ì„œ ì œëª©: {doc['ê·œì •ëª…']}\në‚´ìš©: {doc['ë‚´ìš©']}" for doc in context_docs])
        history_str = "\n".join([f'{msg["role"]}: {msg["content"]}' for msg in chat_history])

        # âœ¨ ê·¹ë„ë¡œ ê°„ê²°í•œ ë‹µë³€ì„ ìœ„í•œ ìµœì¢… í”„ë¡¬í”„íŠ¸
        prompt = f"""ë‹¹ì‹ ì€ í•µì‹¬ë§Œ ë§í•˜ëŠ” ê³¼ë¬µí•œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

### ì§€ì‹œì‚¬í•­:
1.  'ì´ì „ ëŒ€í™”'ì™€ 'ê´€ë ¨ ê·œì • ë‚´ìš©'ì„ ë°”íƒ•ìœ¼ë¡œ 'í˜„ì¬ ì§ˆë¬¸'ì˜ í•µì‹¬ì ì¸ ë‹µ(Fact)ì„ ì°¾ìœ¼ì„¸ìš”.
2.  ë‹¹ì‹ ì˜ ë‹µë³€ì€ **ë°˜ë“œì‹œ ë‹¨ í•œ ë¬¸ì¥**ìœ¼ë¡œë§Œ êµ¬ì„±ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
3.  ì ˆëŒ€ ë¶€ì—° ì„¤ëª…ì„ í•˜ê±°ë‚˜, ë¨¼ì € ì œì•ˆí•˜ê±°ë‚˜, ì¸ì‚¬ë§ì„ í•˜ì§€ ë§ˆì„¸ìš”.
4.  ì˜¤ì§ ì‚¬ì‹¤ì— ê¸°ë°˜í•œ í•œ ë¬¸ì¥ì˜ ë‹µë³€ë§Œ ì œê³µí•˜ê³  ì‚¬ìš©ìì˜ ë‹¤ìŒ ì§ˆë¬¸ì„ ê¸°ë‹¤ë¦¬ì„¸ìš”.

### ì´ì „ ëŒ€í™”:
{history_str}

### ê´€ë ¨ ê·œì • ë‚´ìš©:
{context_str}

### í˜„ì¬ ì§ˆë¬¸:
{query}

### ì „ë¬¸ê°€ì˜ í•œ ë¬¸ì¥ ë‹µë³€:
"""
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"

# --- 3. UI êµ¬ì„± ë° ë©”ì¸ ë¡œì§ ---
st.title("ğŸ”— ì—…ë¬´ê·œì • AI")

sbert_model = load_sbert_model()
data = load_and_embed_data(JSON_FILE_PATH, sbert_model)
if data is None: st.error("ê·œì •ì§‘ ë°ì´í„° íŒŒì¼ì„ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."); st.stop()

if "category" not in st.session_state: st.session_state.category = None
if "messages" not in st.session_state: st.session_state.messages = []

# --- í™”ë©´ ê·¸ë¦¬ê¸° ---
if st.session_state.category is None:
    st.info("í†µí•© ê²€ìƒ‰ ë˜ëŠ” ì¹´í…Œê³ ë¦¬ë³„ ê²€ìƒ‰ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
    if st.button("ğŸŒ ì „ì²´ ê·œì •ì—ì„œ ê²€ìƒ‰", use_container_width=True, type="primary"):
        st.session_state.category = "global"; st.rerun()
    st.markdown("---")
    
    sorted_categories = sorted(CATEGORIES.items(), key=lambda item: int(item[0]))
    for key, value in sorted_categories:
        if st.button(value["name"], key=key, use_container_width=True):
            st.session_state.category = key; st.rerun()
else:
    if st.session_state.category == "global": category_name, files_to_search = "ì „ì²´ ê·œì •", ALL_FILES
    else: info = CATEGORIES[st.session_state.category]; category_name, files_to_search = info['name'], info['files']
    
    st.header(f"ğŸ’¬ {category_name} ê²€ìƒ‰")
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]): st.markdown(msg["content"])

    if prompt := st.chat_input(f"'{category_name}'ì— ëŒ€í•´ ì§ˆë¬¸í•´ë³´ì„¸ìš”..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"): st.markdown(prompt)
        with st.chat_message("assistant"):
            with st.spinner("ê°€ì¥ ì •í™•í•œ ê·œì •ì„ ì°¾ê³  ë‹µë³€ì˜ í•µì‹¬ì„ ìš”ì•½í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                chat_history = st.session_state.messages[-7:-1]
                context_docs = hybrid_search(prompt, data, sbert_model, files_to_search)
                if not context_docs:
                    response = "ê´€ë ¨ ê·œì •ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
                else:
                    response = generate_ultimate_answer(prompt, context_docs, chat_history)
            st.markdown(response)
            st.session_state.messages.append({"role": "assistant", "content": response})

    if st.button("â†©ï¸ ì¹´í…Œê³ ë¦¬ ì„ íƒìœ¼ë¡œ"):
        st.session_state.category = None; st.session_state.messages = []; st.rerun()